{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5b9161-f732-40cb-92d0-b0bd397b03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69f2e43-34a8-4260-b2fa-4e3a38c3bfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts: 50 rows\n",
      "Comments: 1706 rows\n",
      "\n",
      "Posts columns: ['PostID', 'Title', 'Author', 'Score', 'NumComments', 'CreatedUTC']\n",
      "Comments columns: ['CommentID', 'PostID', 'Author', 'Score', 'Body', 'CreatedUTC']\n"
     ]
    }
   ],
   "source": [
    "# Load raw data from Assignment A (file.py)\n",
    "try:\n",
    "    posts_df = pd.read_csv('posts.csv')\n",
    "    comments_df = pd.read_csv('comments.csv')\n",
    "    print(f\"Posts: {len(posts_df)} rows\")\n",
    "    print(f\"Comments: {len(comments_df)} rows\")\n",
    "    print(\"\\nPosts columns:\", posts_df.columns.tolist())\n",
    "    print(\"Comments columns:\", comments_df.columns.tolist())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c325abe0-cba6-4422-9af0-f951e6b01ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts before cleaning: 50\n",
      "Posts after cleaning: 50 (removed 0)\n",
      "Comments before cleaning: 1706\n",
      "Comments after cleaning: 1689 (removed 17)\n"
     ]
    }
   ],
   "source": [
    "#remove [deleted] or [removed] authors and titles\n",
    "posts_clean = posts_df[\n",
    "    (~posts_df['Author'].isin(['[deleted]', '[removed]', 'None'])) &\n",
    "    (~posts_df['Title'].str.contains(r'\\[deleted\\]|\\[removed\\]', case=False, na=False))\n",
    "].copy()\n",
    "\n",
    "# remove [deleted], [removed] content and empty bodies\n",
    "comments_clean = comments_df[\n",
    "    (~comments_df['Author'].isin(['[deleted]', '[removed]', 'None'])) &\n",
    "    (~comments_df['Body'].isin(['[deleted]', '[removed]'])) &\n",
    "    (comments_df['Body'].notna()) &\n",
    "    (comments_df['Body'].str.strip() != '')\n",
    "].copy()\n",
    "\n",
    "print(f\"Posts before cleaning: {len(posts_df)}\")\n",
    "print(f\"Posts after cleaning: {len(posts_clean)} (removed {len(posts_df) - len(posts_clean)})\")\n",
    "print(f\"Comments before cleaning: {len(comments_df)}\")\n",
    "print(f\"Comments after cleaning: {len(comments_clean)} (removed {len(comments_df) - len(comments_clean)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f96773-ae19-43aa-8c1b-4c8c8d9b2029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps converted successful\n",
      "Sample converted dates:\n",
      "Posts: [Timestamp('2025-07-19 05:46:21+0000', tz='UTC'), Timestamp('2025-07-19 05:39:44+0000', tz='UTC')]\n",
      "Comments: [Timestamp('2025-07-19 05:52:29+0000', tz='UTC'), Timestamp('2025-07-19 05:54:26+0000', tz='UTC')]\n"
     ]
    }
   ],
   "source": [
    "def convert_utc_to_datetime(utc_timestamp):\n",
    "    return datetime.fromtimestamp(utc_timestamp, tz=timezone.utc)\n",
    "\n",
    "# Convert timestamps for posts\n",
    "posts_clean['CreatedDate'] = posts_clean['CreatedUTC'].apply(convert_utc_to_datetime)\n",
    "posts_clean['Date'] = posts_clean['CreatedDate'].dt.date\n",
    "posts_clean['Hour'] = posts_clean['CreatedDate'].dt.hour\n",
    "\n",
    "# Convert timestamps for comments\n",
    "comments_clean['CreatedDate'] = comments_clean['CreatedUTC'].apply(convert_utc_to_datetime)\n",
    "comments_clean['Date'] = comments_clean['CreatedDate'].dt.date\n",
    "\n",
    "print(\"Timestamps converted successful\")\n",
    "print(\"Sample converted dates:\")\n",
    "print(f\"Posts: {posts_clean['CreatedDate'].head(2).tolist()}\")\n",
    "print(f\"Comments: {comments_clean['CreatedDate'].head(2).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "036cbcb1-2aa0-4c46-a23c-bd568584f191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated fields added\n",
      "Average comment length: 35.3 words\n",
      "Average title length: 11.7 words\n",
      "\n",
      "Sample data with new fields:\n",
      "  CommentID  CommentLength_chars  CommentLength_words\n",
      "0   n3y7t98                   78                   16\n",
      "1   n3y8162                  329                   45\n",
      "2   n3y7e19                  220                   10\n"
     ]
    }
   ],
   "source": [
    "# Add comment length fields\n",
    "comments_clean['CommentLength_chars'] = comments_clean['Body'].str.len()\n",
    "comments_clean['CommentLength_words'] = comments_clean['Body'].str.split().str.len()\n",
    "\n",
    "# Add post title length fields\n",
    "posts_clean['TitleLength_chars'] = posts_clean['Title'].str.len()\n",
    "posts_clean['TitleLength_words'] = posts_clean['Title'].str.split().str.len()\n",
    "\n",
    "print(\"Calculated fields added\")\n",
    "print(f\"Average comment length: {comments_clean['CommentLength_words'].mean():.1f} words\")\n",
    "print(f\"Average title length: {posts_clean['TitleLength_words'].mean():.1f} words\")\n",
    "\n",
    "# Show sample \n",
    "print(\"\\nSample data with new fields:\")\n",
    "print(comments_clean[['CommentID', 'CommentLength_chars', 'CommentLength_words']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "171b3238-8158-4c98-b7dc-a0eed2d12fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files created:\n",
      "\n",
      "==================================================\n",
      "ASSIGNMENT B SUMMARY\n",
      "==================================================\n",
      "\n",
      "Final cleaned data: 50 posts, 1689 comments\n"
     ]
    }
   ],
   "source": [
    "#Export cleaned data \n",
    "\n",
    "# Save to CSV files\n",
    "posts_clean.to_csv('posts_cleaned.csv', index=False)\n",
    "comments_clean.to_csv('comments_cleaned.csv', index=False)\n",
    "\n",
    "# Save to SQLite database\n",
    "conn = sqlite3.connect('reddit_data_cleaned.db')\n",
    "posts_clean.to_sql('posts', conn, if_exists='replace', index=False)\n",
    "comments_clean.to_sql('comments', conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ASSIGNMENT B SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nFinal cleaned data: {len(posts_clean)} posts, {len(comments_clean)} comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a6cbc-3db1-4b62-9d82-5405c5c90a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
